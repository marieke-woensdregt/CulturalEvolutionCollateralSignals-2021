{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cultural evolution of collatoral signals vs. regular vocabulary\n",
    "\n",
    "\n",
    "## Observation: \n",
    "Corpus work on continuers: Continuer-type collateral signals are:\n",
    "- phonologically less diverse\n",
    "- structurally simpler\n",
    "- shorter than other words\n",
    "\n",
    "## Hypothesis: \n",
    "Collatoral signals have culturally evolved to (i) be short and simple, and (ii) make use of a restricted and distinct subset of phonemes and multimodal elements, because that way they minimise disruption to the flow of conversation. Here we will first focus on continuer signals (like *mmhmm*) specifically, as an example of the broader category of collatoral signals. \n",
    "\n",
    "### Potential sources of disruption:\n",
    "1. **Production effort:** More effortful --> slows down conversation (both time & processing)\n",
    "2. **Confusability with regular vocabulary:** More confusable --> higher processing demands & increased chance of misinterpretation of the function (as content instead of collatoral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2021-04-30 14:05:39 \n",
    "\n",
    "## Modelling framework: Exemplar model\n",
    "\n",
    "Winter & Wedel (2016) about exemplar models: \n",
    "\n",
    "\n",
    "_\"Within this framework, linguistic categories such as a words and sounds are modeled as populations\n",
    "of stored instances or exemplars of that category. A strength of this framework is its ability\n",
    "to account for the observation that speakers’ categorization behavior changes as variants\n",
    "of a category are experienced. Assuming a previously evolved system of discrete\n",
    "linguistic categories, this paper uses this exemplar framework to explore how the distribution\n",
    "of sound categories continues to be influenced by word categories in individuals, and\n",
    "by extension, how the larger system of sound categories in a population can evolve over\n",
    "the course of language change.\" (p. 504)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2021-04-30 14:17:21 \n",
    "\n",
    "## Prediction:\n",
    "\n",
    "Given a model like that of Wedel (2012) and Winter & Wedel (2016), we predict that if we make a distinction between a class of collatoral/continuer words vs. a class of regular vocabulary words, and put the class of collatoral/continuer words under adapted pressures compared to those that the regular vocabulary words are subject to, this will cause the collatoral/continuer words to always end up in the same region of the space, whereas the regular vocabulary words are free to move around. \n",
    "\n",
    "That is, the regulary vocabulary words are truly *arbitrary*: it doesn't matter whether word category 1 ends up in the top-left quadrant of the space or in the bottom-right quadrant, etc.; and the same holds for all other word categories within the regular vocabulary class.\n",
    "The word(s) in the collatoral/continuer class however, are subject to specific pressures that cause the form to be non-arbitrary; meaning that the word(s) in that class always end up in the same region of the possibility space, across independent simulation runs with independent randomised initialisations of the word category clusters.\n",
    "\n",
    "If we'd start working with more than 1 word in the class of continuers, we'd further adapt the pressures such that *within* the class of continuers, the anti-ambiguity bias is minimal. The idea behind this is that it's not important to distinguish *mmhmm* from *mmm*. The corresponding prediction would then be that all words in the continuer class end up clustered together in the same region of the possibility space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replication of Winter & Wedel (2016) / Wedel (2012), with some added features\n",
    "\n",
    "\n",
    "### General features\n",
    "\n",
    "- An **agent** consists of a lexicon of $|W|$ word categories (let's start with 4). One word in that set should be singled out as the *continuer* word. In other words, the entire set of word categories $W$ can be further split up into a set of regular vocabulary words (let's call it $V$) and a set of collatoral/continuer words (let's call it $C$), where $W = V \\cup C$ and $V \\cap C = \\varnothing$. Let's start with $|C| = 1$. For the word(s) in the set $C$, additional and/or adapted pressures will apply. (We want to *increase* the pressure for minimal production effort, and *ease* the pressure for re-use of features; see Section 1.4.4 below.)\n",
    "    - A **word** is represented by a set of exemplars. \n",
    "        - An **exemplar** is represented by a vector that designates a point in an *n*-dimensional space. Let's start with 2 dimensions, and let's have them both range arbitrarily from 0 to 100 (with integer values in between). An example of an exemplar would then be $[15, 25]$ (these individual values in the vector, like 15 and 25, are referred to as \"segments\" by Wedel, 2012).\n",
    "\n",
    "\n",
    "- **Initialisation of an agent:** _\"Both agents’ lexicons are pre-seeded with 100 clustered exemplars of each word category.\"_ (Wedel, 2012) <span class=\"mark\">--> What does clustered mean here exactly? How are these initialised? Just start each word category by choosing a random point in the 2D-space, and then generate the other 99 exemplars around that point? Not sure...</span>\n",
    "\n",
    "### A simulation:\n",
    "\n",
    "- Wedel (2012) talks about 20 independent simulation runs per condition, consisting of 10,000 rounds each. However, the figures usually show the result after 4,000 rounds.\n",
    "- **Round of interactions:** \n",
    "    - _\"Agents take turns talking to each other: In each round, the speaker utters one token of each word in its lexicon, and the listener maps each token to the best fitting category and stores it there as a new exemplar of that category._ (Winter & Wedel, 2016)\n",
    "    - _\"After a speaker has produced an output target for each of its word categories, roles reverse.\"_ (Wedel, 2012; Appendix)\n",
    "    - _\"Agents take turns producing an output from each of their word categories for each other, and likewise take turns categorizing and storing the outputs of the other.\"_ \n",
    "- **Success:**_\"Within the scope of this model, communication is successful to the extent that the listener maps the speaker’s output to the intended word category.\"_\n",
    "\n",
    "\n",
    "### Pressures at play for regular vocabulary\n",
    "\n",
    "\n",
    "#### Production:\n",
    "\n",
    "\n",
    "\n",
    "Production begins by selecting one exemplar from a word category: An exemplar is chosen from the target word category with probability proportional to the exemplar's activation level. \n",
    "\n",
    "##### Activation level\n",
    "- _\"Each new exemplar is associated with an initial activation value that decreases over time (i.e., memory decay; Hintzman, 1986; Nosofsky, 1986; Pierrehumbert, 2001).\"_ (Winter & Wedel, 2016)\n",
    "- _\"Activation is calculated as an exponential function of recency, where exemplars that were stored 100 rounds previously have an activation level that is approximately .1% that of a new exemplar).\"_ (Wedel, 2012)\n",
    "- _\"In the model runs shown here, the activation of a exemplar is modeled as $e^{(.2j)}$, where $j$ is its list position; this results in a exemplar at position 100 having an activation that is approximately .01 times that of an exemplar at position 1.\"_ (Wedel, 2012; Appendix)\n",
    "- _\"The probability of an exemplar being chosen as a production target is its activation relative to the total activation of all exemplars in the category.\"_ (Wedel, 2012; Appendix)\n",
    "- _\"Exemplars at list positions greater than 100 are discarded after every round to keep computation efficient; preserving more exemplars slows the rate of change in the system but otherwise does not qualitatively change system behavior.\"_ (Wedel, 2012; Appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Intermezzo: Worked example for activation level:\n",
    "\n",
    "The text in the body of the 2012 paper and the text in the appendix of the 2012 paper give different ratios of activation for an exemplar at position 1 versus an exemplar at position 100.\n",
    "- The body of the paper says an exemplar at position 100 should have an activation level that is approximately 0.1% that of a new exemplar. Approximately 0.1% = ~0.001 times the activation of a new exemplar.\n",
    "- The appendix, on the other hand, says that an exemplar at position 100 should have an activation level that is approximately 0.01 times that of an exemplar at position 1.\n",
    "\n",
    "To make things even more confusing, neither of these examples from the text correspond with the equation that is given in the appendix: $e^{(.2j)}$ where $j$ is the list position of the exemplar. \n",
    "\n",
    "I would interpret this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T14:46:02.066987Z",
     "start_time": "2022-02-28T14:46:02.050116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "activation_level_position_1 is:\n",
      "1.2214027581601699\n",
      "\n",
      "activation_level_position_100 is:\n",
      "485165195.4097903\n",
      "\n",
      "ratio is:\n",
      "397219665.8050838\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def activation_level_original(j):\n",
    "    return math.exp((0.2*j))\n",
    "\n",
    "activation_level_position_1 = activation_level_original(1)\n",
    "print('')\n",
    "print(\"activation_level_position_1 is:\")\n",
    "print(activation_level_position_1)\n",
    "\n",
    "activation_level_position_100 = activation_level_original(100)\n",
    "print('')\n",
    "print(\"activation_level_position_100 is:\")\n",
    "print(activation_level_position_100)\n",
    "\n",
    "ratio = activation_level_position_100/activation_level_position_1\n",
    "print('')\n",
    "print(\"ratio is:\")\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can **definitely** not be right, because the exemplar at list position 100 has a *higher* activation level than the exemplar at position 1.\n",
    "\n",
    "Could there be a minus sign missing in the exponent? Maybe something went wrong in typesetting the equation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T14:46:02.226636Z",
     "start_time": "2022-02-28T14:46:02.220429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "activation_level_position_1 is:\n",
      "0.8187307530779818\n",
      "\n",
      "activation_level_position_100 is:\n",
      "2.061153622438558e-09\n",
      "\n",
      "ratio is:\n",
      "2.51749871943828e-09\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def activation_level_with_minus(j):\n",
    "    return math.exp((-0.2*j))\n",
    "\n",
    "activation_level_position_1 = activation_level_with_minus(1)\n",
    "print('')\n",
    "print(\"activation_level_position_1 is:\")\n",
    "print(activation_level_position_1)\n",
    "\n",
    "activation_level_position_100 = activation_level_with_minus(100)\n",
    "print('')\n",
    "print(\"activation_level_position_100 is:\")\n",
    "print(activation_level_position_100)\n",
    "\n",
    "ratio = activation_level_position_100/activation_level_position_1\n",
    "print('')\n",
    "print(\"ratio is:\")\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now at least the exemplar at list position 100 has a smaller activation level than the exemplar at list position 1, but the ratio is *way* more exaggerated than the examples given in the text.\n",
    "\n",
    "If we'd want to replicate the examples given in the text (either a ratio of ~0.01 or a ratio of ~0.001), we'd need to use the following numbers instead of 0.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T14:46:02.438346Z",
     "start_time": "2022-02-28T14:46:02.431860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "activation_level_position_1 is:\n",
      "0.9550419621907147\n",
      "\n",
      "activation_level_position_100 is:\n",
      "0.010051835744633586\n",
      "\n",
      "ratio is:\n",
      "0.010525019991348097\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def activation_level_with_minus_and_constant_as_argument(j, constant):\n",
    "    return math.exp((-constant*j))\n",
    "\n",
    "\n",
    "constant = 0.046 \n",
    "\n",
    "activation_level_position_1 = activation_level_with_minus_and_constant_as_argument(1, constant)\n",
    "print('')\n",
    "print(\"activation_level_position_1 is:\")\n",
    "print(activation_level_position_1)\n",
    "\n",
    "activation_level_position_100 = activation_level_with_minus_and_constant_as_argument(100, constant)\n",
    "print('')\n",
    "print(\"activation_level_position_100 is:\")\n",
    "print(activation_level_position_100)\n",
    "\n",
    "ratio = activation_level_position_100/activation_level_position_1\n",
    "print('')\n",
    "print(\"ratio is:\")\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T14:46:02.446070Z",
     "start_time": "2022-02-28T14:46:02.441018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "activation_level_position_1 is:\n",
      "0.933326680078202\n",
      "\n",
      "activation_level_position_100 is:\n",
      "0.0010077854290485105\n",
      "\n",
      "ratio is:\n",
      "0.0010797777997346757\n"
     ]
    }
   ],
   "source": [
    "constant = 0.069\n",
    "\n",
    "activation_level_position_1 = activation_level_with_minus_and_constant_as_argument(1, constant)\n",
    "print('')\n",
    "print(\"activation_level_position_1 is:\")\n",
    "print(activation_level_position_1)\n",
    "\n",
    "activation_level_position_100 = activation_level_with_minus_and_constant_as_argument(100, constant)\n",
    "print('')\n",
    "print(\"activation_level_position_100 is:\")\n",
    "print(activation_level_position_100)\n",
    "\n",
    "ratio = activation_level_position_100/activation_level_position_1\n",
    "print('')\n",
    "print(\"ratio is:\")\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another possibility is that the % sign in the text example in the body of the paper was put there by accident? So that the author actually means a ratio of of ~0.1? Would that bring the constant closer to the 0.2 given in the appendix?\n",
    "\n",
    "What constant would give us something close to a ratio of ~0.1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T14:46:02.680513Z",
     "start_time": "2022-02-28T14:46:02.661771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "activation_level_position_1 is:\n",
      "0.9772624837732771\n",
      "\n",
      "activation_level_position_100 is:\n",
      "0.10025884372280375\n",
      "\n",
      "ratio is:\n",
      "0.10259152007523865\n"
     ]
    }
   ],
   "source": [
    "constant = 0.023\n",
    "\n",
    "activation_level_position_1 = activation_level_with_minus_and_constant_as_argument(1, constant)\n",
    "print('')\n",
    "print(\"activation_level_position_1 is:\")\n",
    "print(activation_level_position_1)\n",
    "\n",
    "activation_level_position_100 = activation_level_with_minus_and_constant_as_argument(100, constant)\n",
    "print('')\n",
    "print(\"activation_level_position_100 is:\")\n",
    "print(activation_level_position_100)\n",
    "\n",
    "ratio = activation_level_position_100/activation_level_position_1\n",
    "print('')\n",
    "print(\"ratio is:\")\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, ok, at least there's a 2 in the constant now. So if we'd imagine there is not only a minus sign missing from the equation as it appears in the appendix, but that there's also a zero missing, and that the % sign in the body of the text was put there by accident, *then* we might get something that more or less works?\n",
    "So in that case, the correct equation would be: $e^{(-0.02j)}$\n",
    "\n",
    "But this would require a lot of creative interpretation...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So we asked Andy Wedel via email.** He writes: \n",
    "$$ \\text{prop} = 2.72 ^{(-j/ \\text{decay})} $$\n",
    "Where *decay* is the total number of exemplars (in most of the runs either 100 or 200) divided by 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T14:46:03.142423Z",
     "start_time": "2022-02-28T14:46:03.136967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "activation_level_position_1 is:\n",
      "0.9511993718183768\n",
      "\n",
      "activation_level_position_100 is:\n",
      "0.006716692712056564\n",
      "\n",
      "ratio is:\n",
      "0.007061288002342223\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "\n",
    "def activation_level_wedel(j):\n",
    "    return 2.72**(-j/(n/5))\n",
    "\n",
    "activation_level_position_1 = activation_level_wedel(1)\n",
    "print('')\n",
    "print(\"activation_level_position_1 is:\")\n",
    "print(activation_level_position_1)\n",
    "\n",
    "activation_level_position_100 = activation_level_wedel(100)\n",
    "print('')\n",
    "print(\"activation_level_position_100 is:\")\n",
    "print(activation_level_position_100)\n",
    "\n",
    "ratio = activation_level_position_100/activation_level_position_1\n",
    "print('')\n",
    "print(\"ratio is:\")\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, this number 2.72 must come from Euler's number. So to make things a bit cleaner, let's use this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T14:46:03.361887Z",
     "start_time": "2022-02-28T14:46:03.356296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "activation_level_position_1 is:\n",
      "0.951229424500714\n",
      "\n",
      "activation_level_position_100 is:\n",
      "0.006737946999085467\n",
      "\n",
      "ratio is:\n",
      "0.00708340892905212\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "n = 100\n",
    "\n",
    "def activation_level_wedel(j):\n",
    "    return math.exp((-j/(n/5)))\n",
    "\n",
    "activation_level_position_1 = activation_level_wedel(1)\n",
    "print('')\n",
    "print(\"activation_level_position_1 is:\")\n",
    "print(activation_level_position_1)\n",
    "\n",
    "activation_level_position_100 = activation_level_wedel(100)\n",
    "print('')\n",
    "print(\"activation_level_position_100 is:\")\n",
    "print(activation_level_position_100)\n",
    "\n",
    "ratio = activation_level_position_100/activation_level_position_1\n",
    "print('')\n",
    "print(\"ratio is:\")\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Model description continued:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a target exemplar has been selected on the basis of its activation level, two different similarity biases are applied to it:\n",
    "\n",
    "##### Similarity biases:\n",
    "\n",
    "Consist of the following two components:\n",
    "\n",
    "- **Within-word category similarity bias:** _\"The segment exemplar values of this initial word target are stochastically biased toward the value at the same positions in all the word exemplars within the category\"_\n",
    "    - _\"At the word level, population vectors are calculated for the segment values in the target word relative to all segment values at the same position over all exemplars within that word category\"_ (Wedel, 2012; Appendix)\n",
    "\n",
    "- **Within-segment-dimension similarity bias:** _\"each individual segment exemplar value in the target is also stochastically biased toward all other segment exemplars that reference the same dimension across the entire lexicon\"_ \n",
    "    - _\"At the segment level, population vectors are calculated for the segment values in the target word relative to all segment values on that dimension across the lexicon.\"_ (Wedel, 2012; Appendix)\n",
    "\n",
    "- _\"The population vector with respect to a particular point within a particular segment dimension is a weighted average of all segment exemplars mapped to the category, where both the Euclidean distance from the target exemplar and activation influence each exemplar’s contribution. This is conceptually the same as Nosofsky’s Generalized Context model (Nosofsky 1988), modified to take exemplar activation into account. The formula used to incorporate these factors is given below, where $p$ is the output population vector, y is each position within the segment dimension value of the target under production, $w_{y}$ is the activation of the exemplar, $x$ is the reference point chosen as the basis for production, and $k$ is a scaling factor influencing the fall off of the contribution to the population vector of the point $y$ relative to $x$:\"_ (Wedel, 2012; Appendix)\n",
    "\n",
    "$$ p = \\frac{\\sum_y yw_{y} e^{-k |x-y|}}{\\sum_{y} w_{y} e^{-k |x-y|}} $$\n",
    "\n",
    "- _\"The value of $k$ used in the simulations shown here is 0.2; a larger value of $k$ reduces the effect of more distant values on the population vector.\"_ (Wedel, 2012; Appendix). --> Let us start with $k = 0.2$ as well, but make $k$ into a parameter that we can change just in case.\n",
    "\n",
    "\n",
    "- _\"To model the influence of both word and segment recency and similarity on production variation, the population vectors at each segment dimension at each level are combined to create a new output that combines information from both within-word category, and within-lexicon sources. The relative contribution of word versus segment population vectors to the output was fixed at .9.\"_ (Wedel, 2012; Appendix). I wasn't immediately sure how to interpret this, but I think the following is the most likely interpretation:\n",
    "    - I think it's clear that the final output vector should be a weighted average of the within-word and within-segment population vectors. And I'm assuming the weight of one of them should be 0.9, while the weight of the other is 1.0. (When expressed as a fraction, the 0.9:1 ratio corresponds to 0.9.)\n",
    "    - <span class=\"mark\">I'm not 100% sure which way around these weightings should be</span>, but I think the most plausible interpretation is that word:segment = 0.9:1.0. Meaning that the weight of the within-word population vector is 0.9, while the weight of the within-segment population vector is 1.0.\n",
    "    \n",
    "--> **We found this in the scripts that Andy Wedel sent us:** \n",
    "\n",
    "$$ \\$outword[\\$a] = ((9*\\$outword[\\$a]) + \\$outsounds[\\$a])/10 $$\n",
    "\n",
    "where $\\$outword$ is the population vector for the within-word similarity bias, and $\\$outsounds$ is the population vector for the within-segment similarity bias.\n",
    "--> So it's actually $(0.9*outword) + (0.1*outsounds)$\n",
    "\n",
    "--> And a comment in Andy's code indeed says: \"*For the Winter/Wedel paper, we used a proportion of .9 of the word-based bias to .1 of the sound based bias.*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Intermezzo: Worked example for similarity biases:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Within-word category similarity bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T14:46:04.219054Z",
     "start_time": "2022-02-28T14:46:04.194873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "dimension is:\n",
      "0\n",
      "x is:\n",
      "15\n",
      "y_values are:\n",
      "[15 16 18 12]\n",
      "w_y_values are:\n",
      "[0.4 0.3 0.2 0.1]\n",
      "numerator is:\n",
      "12.564203468025639\n",
      "denominator is:\n",
      "0.8102627167516026\n",
      "p for dimension 0 is:\n",
      "15.506332956298879\n",
      "\n",
      "\n",
      "dimension is:\n",
      "1\n",
      "x is:\n",
      "25\n",
      "y_values are:\n",
      "[25 26 28 23]\n",
      "w_y_values are:\n",
      "[0.4 0.3 0.2 0.1]\n",
      "numerator is:\n",
      "21.001181142016776\n",
      "denominator is:\n",
      "0.8224135577457639\n",
      "p for dimension 1 is:\n",
      "25.536034692303748\n",
      "\n",
      "pop_vector_within_word is:\n",
      "[15.506332956298879, 25.536034692303748]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np # to create arrays that are easily manipulated along differen axes\n",
    "\n",
    "# Worked example for within-word category similarity bias:\n",
    "\n",
    "# Imagine these are all the exemplars across all different word categories \n",
    "# (in the full model there'd be 100 exemplars per category, rather than 4):\n",
    "\n",
    "# word category 1:\n",
    "exemplar_1_1 = [15, 25]\n",
    "exemplar_1_2 = [16, 26]\n",
    "exemplar_1_3 = [18, 28]\n",
    "exemplar_1_4 = [12, 23]\n",
    "\n",
    "# word category 2:\n",
    "exemplar_2_1 = [70, 31]\n",
    "exemplar_2_2 = [68, 29]\n",
    "exemplar_2_3 = [73, 32]\n",
    "exemplar_2_4 = [72, 30]\n",
    "\n",
    "# word category 3:\n",
    "exemplar_3_1 = [21, 72]\n",
    "exemplar_3_2 = [19, 77]\n",
    "exemplar_3_3 = [23, 70]\n",
    "exemplar_3_4 = [20, 75]\n",
    "\n",
    "# word category 4:\n",
    "exemplar_4_1 = [76, 65]\n",
    "exemplar_4_2 = [72, 68]\n",
    "exemplar_4_3 = [78, 64]\n",
    "exemplar_4_4 = [74, 69]\n",
    "\n",
    "# And imagine they have the following (normalised) activation levels:\n",
    "\n",
    "# word category 1:\n",
    "activation_ex_1_1 = 0.4\n",
    "activation_ex_1_2 = 0.3\n",
    "activation_ex_1_3 = 0.2\n",
    "activation_ex_1_4 = 0.1\n",
    "\n",
    "# word category 2:\n",
    "activation_ex_2_1 = 0.65\n",
    "activation_ex_2_2 = 0.15\n",
    "activation_ex_2_3 = 0.1\n",
    "activation_ex_2_4 = 0.1\n",
    "\n",
    "# word category 3:\n",
    "activation_ex_3_1 = 0.5\n",
    "activation_ex_3_2 = 0.3\n",
    "activation_ex_3_3 = 0.15\n",
    "activation_ex_3_4 = 0.05\n",
    "\n",
    "# word category 4:\n",
    "activation_ex_4_1 = 0.7\n",
    "activation_ex_4_2 = 0.2\n",
    "activation_ex_4_3 = 0.05\n",
    "activation_ex_4_4 = 0.05\n",
    "\n",
    "# This allows us to construct the speaker's lexicon as follows:\n",
    "\n",
    "speaker_lexicon = np.array([[exemplar_1_1, exemplar_1_2, exemplar_1_3, exemplar_1_4],\n",
    "                    [exemplar_2_1, exemplar_2_2, exemplar_2_3, exemplar_2_4],\n",
    "                    [exemplar_3_1, exemplar_3_2, exemplar_3_3, exemplar_3_4],\n",
    "                    [exemplar_4_1, exemplar_4_2, exemplar_4_3, exemplar_4_4]])\n",
    "\n",
    "\n",
    "speaker_activations = np.array([[activation_ex_1_1, activation_ex_1_2, activation_ex_1_3, activation_ex_1_4],\n",
    "                        [activation_ex_2_1, activation_ex_2_2, activation_ex_2_3, activation_ex_2_4],\n",
    "                        [activation_ex_3_1, activation_ex_3_2, activation_ex_3_3, activation_ex_3_4],\n",
    "                        [activation_ex_4_1, activation_ex_4_2, activation_ex_4_3, activation_ex_4_4]])\n",
    "\n",
    "\n",
    "# Now imagine exemplar_1_1 is chosen as the exemplar to be produced, \n",
    "# based on its activation level\n",
    "\n",
    "# For each segment of exemplar_1_1, we then first calculate a population vector,\n",
    "# using the segment values at the same position (i.e. 1st dimension or 2nd dimension)\n",
    "# from all other exemplars within that same word category.\n",
    "# That population vector is a weighted average of all segment exemplars mapped to the\n",
    "# category, using Equation 1.\n",
    "# First, let's translate Equation 1 to a function:\n",
    "\n",
    "def population_vector(x, y_values, w_y_values, k):\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for i in range(len(y_values)):\n",
    "        y = y_values[i]\n",
    "        w_y = w_y_values[i]\n",
    "        numerator += y*w_y*math.exp(-k*abs(x-y))\n",
    "        denominator += w_y*math.exp(-k*abs(x-y))\n",
    "    print(\"numerator is:\")\n",
    "    print(numerator)\n",
    "    print(\"denominator is:\")\n",
    "    print(denominator)\n",
    "    p = numerator/denominator\n",
    "    return p\n",
    "\n",
    "\n",
    "# Now let's figure out what the relevant input arguments \n",
    "# for the population_vector function are:\n",
    "# We have to calculate a separate population vector for each dimension.\n",
    "# Let's start with the 1st dimension:\n",
    "# We said that exemplar_1_1 was chosen as the reference point for production,\n",
    "# based on its activation level. That means that x for the 1st dimension should\n",
    "# be 15.\n",
    "# Consequently the y_values for the first dimension should be [15, 16, 18, 12].\n",
    "# Let's write a function to easily grab these values and calculate the population vector\n",
    "# for the two different dimensions:\n",
    "\n",
    "def similarity_bias_within_word(lexicon, activations, word_index, exemplar_index, k):\n",
    "    reference_exemplar = lexicon[word_index][exemplar_index]\n",
    "    p_per_dimension = []\n",
    "    for dimension in range(len(reference_exemplar)):\n",
    "        print('')\n",
    "        print('')\n",
    "        print(\"dimension is:\")\n",
    "        print(dimension)\n",
    "        x = reference_exemplar[dimension]\n",
    "        print(\"x is:\")\n",
    "        print(x)\n",
    "        y_values = lexicon[word_index][:,dimension]\n",
    "        print(\"y_values are:\")\n",
    "        print(y_values)\n",
    "        w_y_values = activations[word_index]\n",
    "        print(\"w_y_values are:\")\n",
    "        print(w_y_values)\n",
    "        p = population_vector(x, y_values, w_y_values, k)\n",
    "        print(\"p for dimension \"+str(dimension)+\" is:\")\n",
    "        print(p)\n",
    "        p_per_dimension.append(p)\n",
    "    return p_per_dimension\n",
    "        \n",
    "        \n",
    "# Let's set k to 0.2, as in Wedel (2012):\n",
    "k = 0.2\n",
    "\n",
    "# Finally, we need the index of the target word and the selected reference exemplar. \n",
    "# These should both be 0, because we said the target was word category 1, \n",
    "# and exemplar_1_1 was chosen based on its activation level.\n",
    "target_word_index = 0\n",
    "reference_exemplar_index = 0\n",
    "\n",
    "pop_vector_within_word = similarity_bias_within_word(speaker_lexicon, speaker_activations, target_word_index, reference_exemplar_index, k)\n",
    "print('')\n",
    "print(\"pop_vector_within_word is:\")\n",
    "print(pop_vector_within_word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T08:54:03.010001Z",
     "start_time": "2021-05-10T08:54:03.007548Z"
    }
   },
   "source": [
    "As we can see if we run the code block above, both segment values of the reference exemplar (originally [15, 25]) get moved upwards after the within-word category similarity bias has been applied. From 15 to 15.51, and from 25 to 25.54.\n",
    "\n",
    "This makes sense, because if we look at the other exemplar within the category and their activation levels, we see that most other exemplars within the category (exemplars 1_2 and 1_3) have slightly higher segment values than the reference exemplar that was chosen (exemplar_1_1).\n",
    "The only exemplar that has lower values than the reference exemplar (exemplar_1_4) has a relatively low activation level, and therefore contributes less to the shift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Within-segment similarity bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T14:46:04.622641Z",
     "start_time": "2022-02-28T14:46:04.611465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "dimension is:\n",
      "0\n",
      "x is:\n",
      "15\n",
      "y_values are:\n",
      "[15 16 18 12 70 68 73 72 21 19 23 20 76 72 78 74]\n",
      "w_y_values are:\n",
      "[0.4  0.3  0.2  0.1  0.65 0.15 0.1  0.1  0.5  0.3  0.15 0.05 0.7  0.2\n",
      " 0.05 0.05]\n",
      "numerator is:\n",
      "19.353971560385215\n",
      "denominator is:\n",
      "1.1443598956094228\n",
      "p for dimension 0 is:\n",
      "16.912486740090067\n",
      "\n",
      "\n",
      "dimension is:\n",
      "1\n",
      "x is:\n",
      "25\n",
      "y_values are:\n",
      "[25 26 28 23 31 29 32 30 72 77 70 75 65 68 64 69]\n",
      "w_y_values are:\n",
      "[0.4  0.3  0.2  0.1  0.65 0.15 0.1  0.1  0.5  0.3  0.15 0.05 0.7  0.2\n",
      " 0.05 0.05]\n",
      "numerator is:\n",
      "30.94231979288734\n",
      "denominator is:\n",
      "1.1474077222633343\n",
      "p for dimension 1 is:\n",
      "26.96715316840613\n",
      "\n",
      "pop_vector_within_segment is:\n",
      "[16.912486740090067, 26.96715316840613]\n"
     ]
    }
   ],
   "source": [
    "# Now let's do a worked example for the within-segment similarity bias:\n",
    "\n",
    "# We can reuse the population_vector() and similarity_bias() functions defined above.\n",
    "# The only difference is that now we give the entire lexicon (i.e. all exemplars,\n",
    "# across word categories) as input, rather than only the within word category exemplars:\n",
    "\n",
    "def similarity_bias_within_segment(lexicon, activations, word_index, exemplar_index, k):\n",
    "    reference_exemplar = lexicon[word_index][exemplar_index]\n",
    "    p_per_dimension = []\n",
    "    for dimension in range(len(reference_exemplar)):\n",
    "        print('')\n",
    "        print('')\n",
    "        print(\"dimension is:\")\n",
    "        print(dimension)\n",
    "        x = reference_exemplar[dimension]\n",
    "        print(\"x is:\")\n",
    "        print(x)\n",
    "        y_values = lexicon[:,:,dimension].flatten()\n",
    "        print(\"y_values are:\")\n",
    "        print(y_values)\n",
    "        w_y_values = activations.flatten()\n",
    "        print(\"w_y_values are:\")\n",
    "        print(w_y_values)\n",
    "        p = population_vector(x, y_values, w_y_values, k)\n",
    "        print(\"p for dimension \"+str(dimension)+\" is:\")\n",
    "        print(p)\n",
    "        p_per_dimension.append(p)\n",
    "    return p_per_dimension\n",
    "\n",
    "pop_vector_within_segment = similarity_bias_within_segment(speaker_lexicon, speaker_activations, target_word_index, reference_exemplar_index, k)\n",
    "print('')\n",
    "print(\"pop_vector_within_segment is:\")\n",
    "print(pop_vector_within_segment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run the code cell above, we see that again the segment values are increased compared to the original target/reference exemplar ([15, 25]): 15 gets changed to 16.91, and 25 gets changed to 26.97.\n",
    "\n",
    "This makes sense, because I constructed the other exemplars in the lexicon in such a way that they all have higher values on each of the segments than the original target/reference exemplar has."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Combining the two similarity biases:\n",
    "\n",
    "Now the last step is to combine the resulting pop_vector_within_word and pop_vector_within_segment with each other. Wedel (2012; Appendix) says:\n",
    "\n",
    "_\"To model the influence of both word and segment recency and similarity on production variation, the population vectors at each segment dimension at each level are combined to create a new output that combines information from both within-word category, and within-lexicon sources. The relative contribution of word versus segment population vectors to the output was fixed at .9.\"_\n",
    "\n",
    "I wasn't immediately sure how to interpret this, but I think the following is the most likely interpretation:\n",
    "- I think it's clear that the final output vector should be a weighted average of the within-word and within-segment population vectors. <span class=\"burk\">And I'm assuming the weight of one of them should be 0.9, while the weight of the other is 1.0. (When expressed as a fraction, the 0.9:1 ratio corresponds to 0.9.)</span>\n",
    "- <span class=\"burk\">I'm not 100% sure about the relative weightings, but I think the most plausible interpretation is that word:segment = 0.9:1.0. Meaning that the weight of the within-word population vector is 0.9, while the weight of the within-segment population vector is 1.0.</span>\n",
    "\n",
    "<span class=\"mark\">---> This turned out to be the wrong inference.</span> Andy writes in his script for the Winter & Wedel (2016) model: \n",
    "_``For the Winter/Wedel paper, we used a proportion of .9 of the word-based bias to .1 of the sound based bias.\"_\n",
    "\n",
    "\n",
    "This would yield the following outcome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T14:46:05.023737Z",
     "start_time": "2022-02-28T14:46:05.017247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_vector is:\n",
      "[15.646948334677997, 25.679146539913987]\n",
      "\n",
      "sum(combined_vector) is:\n",
      "41.32609487459199\n"
     ]
    }
   ],
   "source": [
    "def combine_pop_vectors(word_vector, segment_vector, word_weight, segment_weight):\n",
    "    combined_vector = []\n",
    "    for dimension in range(len(word_vector)):\n",
    "        word_value = word_vector[dimension]\n",
    "        segment_value = segment_vector[dimension]\n",
    "        weighted_avg = ((word_value*word_weight) + (segment_value*segment_weight)) / (word_weight+segment_weight)\n",
    "        combined_vector.append(weighted_avg)\n",
    "    return combined_vector\n",
    "\n",
    "word_weight = 0.9\n",
    "segment_weight = 0.1\n",
    "\n",
    "combined_vector = combine_pop_vectors(pop_vector_within_word, pop_vector_within_segment, word_weight, segment_weight)\n",
    "print(\"combined_vector is:\")\n",
    "print(combined_vector)\n",
    "print('')\n",
    "print(\"sum(combined_vector) is:\")\n",
    "print(sum(combined_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put the combined_vector next to the original within-word population vector and within-segment population vector again:\n",
    "\n",
    "- pop_vector_within_word is: [15.51, 25.54]\n",
    "- pop_vector_within_segment is: [16.91, 26.97]\n",
    "- combined_vector is: [15.65, 25.68]\n",
    "\n",
    "This makes sense. It looks like a weighted average where the within-word population vector has had a more influence than the within-segment population vector.\n",
    "Because if we had just taken the unweighted average, it would have been:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T14:46:05.236091Z",
     "start_time": "2022-02-28T14:46:05.230887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unweighted_average is:\n",
      "[16.20940985 26.25159393]\n",
      "\n",
      "np.sum(unweighted_average) is:\n",
      "42.46100377854941\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "unweighted_average = np.mean((np.array(pop_vector_within_word), np.array(pop_vector_within_segment)), axis=0)\n",
    "print(\"unweighted_average is:\")\n",
    "print(unweighted_average)\n",
    "print('')\n",
    "print(\"np.sum(unweighted_average) is:\")\n",
    "print(np.sum(unweighted_average))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the fact that the values of the weighted average are lower (i.e. closer to the within-word population vector) than the values of this unweighted average, we see that the within-word population vector has had more influence on the combined vector than the within-segment population vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Model description continued:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random noise (i.e. minimal-effort pressure):\n",
    "\n",
    "_\"Noise is added to values of the output target by adding a normally distributed random value. This random value is biased slightly toward the center of the dimension, (i.e. a scale value of 50), in a simple model of production-based lenition (Pierrehumbert 2001; see also e.g. Lindblom et al. 1984 for arguments that the packing of phoneme inventories is in part a consequence of effort-minimization processes). The results described below do not depend on this lenition bias, but they contribute to the illustration by imposing a tendency for each segment exemplar distribution to drift toward the center of each dimension which encourages category merger (see discussion below).\"_ \n",
    "\n",
    "- _\"Finally, a Gaussian random variable with a standard deviation of 3 is added to the output to introduce noise. This variable is biased slightly toward the center of the dimensional space, creating a fixed attractor at the center of each segment dimension in the system. The bias is calculated using a parabolic response curve given below, where $b$ is the bias added to the output population vector, $p$ is the output population vector, $N$ is the number of points in the space and $G$ is a constant; $b$ is subtracted from outputs greater than $N/2$ (here, 50) and added to those below it.\"_ (Wedel, 2012; Appendix)\n",
    "    \n",
    "$$ b = \\frac{(p-N/2)^2}{G}$$\n",
    "\n",
    "- _\"The value of G used in these simulations was 5000, giving a bias toward the center of 0.5 at the edges of the continuum. All else being equal, this bias shifts the distributions of both categories toward the center of the dimension over time, i.e. toward 50, which corresponds to a simple model of articulatory undershoot (cf. Lindblom 1983; Pierrehumbert 2001).\"_ (Wedel, 2012; Appendix)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Intermezzo: Worked example for random noise:\n",
    "\n",
    "Imagine the target output vector is: [15.65, 25.68]\n",
    "\n",
    "(as was the output of applying and combining the similarity biases above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T14:46:06.051173Z",
     "start_time": "2022-02-28T14:46:06.047398Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "g = 5000\n",
    "\n",
    "def bias(p, n, g):\n",
    "    b = ((p - (n/2))**2)/g\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text in the appendix of Wedel (2012) gives a worked example: $G=5000$ should give \"a bias toward the center of 0.5 at the edges of the continuum\". Let's check this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T14:46:06.277066Z",
     "start_time": "2022-02-28T14:46:06.272894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias_edge_left is:\n",
      "0.5\n",
      "bias_edge_right is:\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "bias_edge_left = bias(0, n, g)\n",
    "print(\"bias_edge_left is:\")\n",
    "print(bias_edge_left)\n",
    "\n",
    "bias_edge_right = bias(100, n, g)\n",
    "print(\"bias_edge_right is:\")\n",
    "print(bias_edge_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This matches the example given in the appendix of Wedel (2012)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T14:46:06.517513Z",
     "start_time": "2022-02-28T14:46:06.510608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dimension is:\n",
      "0\n",
      "b is:\n",
      "0.23602643174405652\n",
      "\n",
      "dimension is:\n",
      "1\n",
      "b is:\n",
      "0.11830078260539556\n",
      "\n",
      "biased_means are:\n",
      "[15.882974766422054, 25.797447322519382]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = 100\n",
    "g = 5000\n",
    "output_vector = combined_vector # the values of this are: [16.246413895136346, 26.28925494288395]\n",
    "\n",
    "def apply_bias(output_vector, n, g):\n",
    "    biased_vector = []\n",
    "    for dimension in range(len(output_vector)):\n",
    "        print('')\n",
    "        print(\"dimension is:\")\n",
    "        print(dimension)\n",
    "        p = output_vector[dimension]\n",
    "        b = bias(p, n, g)\n",
    "        print('b is:')\n",
    "        print(b)\n",
    "        if p < (n/2):\n",
    "            biased_mean = p+b\n",
    "        else:\n",
    "            biased_mean = p-b\n",
    "        biased_vector.append(biased_mean)\n",
    "    return biased_vector\n",
    "            \n",
    "biased_means = apply_bias(output_vector, n, g)\n",
    "print('')\n",
    "print(\"biased_means are:\")\n",
    "print(biased_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The biased_means of [15.88, 25.80] (given $G=5000$) makes sense, because the idea is that the values should move closer to the centre of the space (i.e. 50 and 50)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is then to add random noise by choosing a value from a normal distribution with these new biased values as the mean, and a standard deviation of 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T14:46:06.930664Z",
     "start_time": "2022-02-28T14:46:06.924569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "noisy_output is:\n",
      "[16.935407014495087, 28.753089612021437]\n"
     ]
    }
   ],
   "source": [
    "std = 3\n",
    "\n",
    "def add_noise(biased_means, std):\n",
    "    noisy_segments = []\n",
    "    for biased_segment in biased_means:\n",
    "        noisy_segment = np.random.normal(biased_segment, std, 1)\n",
    "        noisy_segments.append(noisy_segment[0])\n",
    "    return noisy_segments\n",
    "\n",
    "noisy_output = add_noise(biased_means, std)\n",
    "print('')\n",
    "print(\"noisy_output is:\")\n",
    "print(noisy_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Model description continued:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perception:\n",
    "        \n",
    "The listener _\"begins the categorization process by calculating the similarity of the speaker output to each category’s stored word exemplars given their activations, in a variant of the Generalized Context Model (Nosofsky 1988). The overall similarities of the speaker output to each category are interpreted as a relative goodness of fit, and the speaker output is then stored as a new exemplar in the best fitting category.\"_\n",
    "- _\"The listener compares the speaker’s output to all of its word exemplars in each category, calculates a sum similarity score for each category using the Generalized Context Model for categorization (Nosofsky 1988), again modified to take activation into account as above in (1), where the scaling factor $k$ is again .2. The speaker output is then stored as a new exemplar in the best fitting listener word category.\"_ (Wedel, 2012; Appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Intermezzo: Worked example for perception:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The (1) mentioned in the text above corresponds to our Equation 2 in this jupyter notebook: i.e., the one that we used for calculating the population vectors for the similarity biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is that the listener calculates the distance of this input vector to the exemplars of each word category in their own lexicon, using Equation 2. Let's first have a look at Equation 2 again (repeated below as Equation 5):\n",
    "\n",
    "\n",
    "- _\"The population vector with respect to a particular point within a particular segment dimension is a weighted average of all segment exemplars mapped to the category, where both the Euclidean distance from the target exemplar and activation influence each exemplar’s contribution. This is conceptually the same as Nosofsky’s Generalized Context model (Nosofsky 1988), modified to take exemplar activation into account. The formula used to incorporate these factors is given below, where $p$ is the output population vector, y is each position within the segment dimension value of the target under production, $w_{y}$ is the activation of the exemplar, $x$ is the reference point chosen as the basis for production, and $k$ is a scaling factor influencing the fall off of the contribution to the population vector of the point $y$ relative to $x$:\"_ (Wedel, 2012; Appendix)\n",
    "\n",
    "$$ p = \\frac{\\sum_y yw_{y} e^{-k |x-y|}}{\\sum_{y} w_{y} e^{-k |x-y|}} $$\n",
    "\n",
    "- _\"The value of $k$ used in the simulations shown here is 0.2; a larger value of $k$ reduces the effect of more distant values on the population vector.\"_ (Wedel, 2012; Appendix). --> Let us start with $k = 0.2$ as well, but make $k$ into a parameter that we can change just in case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's have a look at this Nosofsky (1988) paper that they refer to. It has the following two equations in the section on \"Classification\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T14:46:08.163377Z",
     "start_time": "2022-02-28T14:46:08.138261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "image/png": {
       "height": 465,
       "width": 573
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(\"Nosofsky_1988_Similarity_Equation.png\", width = 573, height = 465)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosofsky's (1988) Equation 4 corresponds to the last part seen both the numerator and denominator of Wedel's (2012) Equation 1. This is the part that takes a distance measure, and turns it into a similarity score.\n",
    "\n",
    "In addition to that, we also want to multiply the similarity score for each exemplar within a given category with its activation level (see quotes about perception from Wedel). The idea behind this must be that the more recent the exemplar, the more influence it should have. (I.e. if two exemplars from a given category are equally distant from the input exemplar, the most recent of the two should have a greater influence on the similarity score than the older one.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T14:46:08.356458Z",
     "start_time": "2022-02-28T14:46:08.347324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "similarity_1_1 is:\n",
      "0.5926545765453743\n",
      "\n",
      "similarity_1_3 is:\n",
      "0.2963272882726872\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Let's first create a listener. \n",
    "# To keep things simple, let's make it the same as the speaker:\n",
    "\n",
    "listener_lexicon = speaker_lexicon\n",
    "\n",
    "listener_activations = speaker_activations\n",
    "\n",
    "# Let's take some example exemplars from this lexicon as defined above:\n",
    "# exemplar_1_1 = [15, 25]\n",
    "# exemplar_1_3 = [18, 28]\n",
    "# with the following corresponding activation levels:\n",
    "#activation_ex_1_1 = 0.4\n",
    "#activation_ex_1_3 = 0.2\n",
    "\n",
    "# Now let's imagine the listener gets the following vector as input from the speaker \n",
    "# (right in the middle between exemplar_1_1 and exemplar_1_3):\n",
    "\n",
    "speaker_output = [16.5, 26.5]\n",
    "\n",
    "def similarity_score(category_exemplar, category_exemplar_activation, input_exemplar, k):\n",
    "    sum_similarity = 0.\n",
    "    for dimension in range(len(input_exemplar)):\n",
    "        input_exemplar_value = input_exemplar[dimension]\n",
    "        category_exemplar_value = category_exemplar[dimension]\n",
    "        distance = abs(input_exemplar_value-category_exemplar_value)\n",
    "        similarity = math.exp(-k*distance)\n",
    "        weighted_similarity = similarity*category_exemplar_activation\n",
    "        sum_similarity += weighted_similarity\n",
    "    return sum_similarity\n",
    "        \n",
    "k = 0.2\n",
    "\n",
    "similarity_1_1 = similarity_score(exemplar_1_1, activation_ex_1_1, speaker_output, k)\n",
    "print('')\n",
    "print(\"similarity_1_1 is:\")\n",
    "print(similarity_1_1)\n",
    "\n",
    "similarity_1_3 = similarity_score(exemplar_1_3, activation_ex_1_3, speaker_output, k)\n",
    "print('')\n",
    "print(\"similarity_1_3 is:\")\n",
    "print(similarity_1_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems to work at least: the similarity score for exemplar_1_3 comes out as lower, even though the distances are pretty much the same, because exemplar_1_3 has a lower activation level (half that of exemplar_1_1, to be exact). And we see that the similarity score of exemplar_1_3 indeed comes out as about half that of exemplar_1_1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T14:46:08.548473Z",
     "start_time": "2022-02-28T14:46:08.542922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category_similarities are:\n",
      "[1.5221998119928382, 0.438217964235963, 0.4510492707459754, 0.00041301987043249446]\n"
     ]
    }
   ],
   "source": [
    "def sum_similarity_category(category_exemplars, exemplar_activations, input_exemplar, k):\n",
    "    sum_similarity = 0.\n",
    "    for i in range(len(category_exemplars)):\n",
    "        exemplar = category_exemplars[i]\n",
    "        activation = exemplar_activations[i]\n",
    "        similarity = similarity_score(exemplar, activation, input_exemplar, k)\n",
    "        sum_similarity += similarity\n",
    "    return sum_similarity\n",
    "\n",
    "\n",
    "def similarity_per_category(word_categories, activations, input_exemplar, k):\n",
    "    similarity_per_word_category = []\n",
    "    for i in range(len(word_categories)):\n",
    "        word = word_categories[i]\n",
    "        exemplar_activations = activations[i]\n",
    "        similarity = sum_similarity_category(word, exemplar_activations, input_exemplar, k)\n",
    "        similarity_per_word_category.append(similarity)\n",
    "    return similarity_per_word_category\n",
    "\n",
    "\n",
    "category_similarities = similarity_per_category(listener_lexicon, listener_activations, speaker_output, k)\n",
    "print(\"category_similarities are:\")\n",
    "print(category_similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks right at least, in the sense that the speaker_output fits word category 1 the best, fits word categories 2 and 3 equally moderately, and fits word category 4 the worst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Model description continued:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Anti-ambiguity bias\n",
    "\n",
    "- From Winter & Wedel (2016): _\"A final feature of the model is a bias against confusability of word perception, that is, an anti-ambiguity bias. The bias is implemented as follows: the probability of successful identification of an output with a word category is proportional to the degree to which the output uniquely maps to that category and to no other. In this way, distinctive speaker outputs are more likely to be stored than ambiguous outputs, with the result that distinctive phonetic values contribute more to the continuing evolution of the lexicon, both at the word and sound levels.\"_\n",
    "- From Wedel (2012): _\"When a speaker output is assigned to the best fitting category, it has a probability of being stored as a new exemplar that is the same as its calculated relative fit that category. For example, if the relative fit of a token to the best fitting category is .9, it has a 90% chance of being stored and a 10% chance of being discarded.\"_\n",
    "- _\"An anti-ambiguity bias is included at the level of the listener in this model in the form of a probability that a speaker output will not be stored as a new exemplar in the best-fitting category. This probability is the reciprocal of the similarity of that output to that category as calculated above, divided by the sum of its similarity to all categories. For example, if the similarity of a speaker output to the best fitting category is .9 relative to all categories, it will have a probability of .1 of not being stored.\"_ (Wedel, 2012; Appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Intermezzo: Worked example for anti-ambiguity bias:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so here we need to take the output from the similarity_per_category() function, and calculate the *relative* fit of each category. I think that only means normalising the category_similarities values over all categories, thereby turning them into probabilities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T14:46:09.532226Z",
     "start_time": "2022-02-28T14:46:09.527803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative_fit_probabilities are:\n",
      "[0.6311258312209148, 0.1816914407394898, 0.18701148408923896, 0.00017124395035642603]\n",
      "\n",
      "sum(relative_fit_probabilities) is:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def relative_fit(category_similarities):\n",
    "    normalised_similarities = []\n",
    "    for similarity in category_similarities:\n",
    "        normalised_fit = similarity/sum(category_similarities)\n",
    "        normalised_similarities.append(normalised_fit)\n",
    "    return normalised_similarities\n",
    "\n",
    "relative_fit_probabilities = relative_fit(category_similarities)\n",
    "print(\"relative_fit_probabilities are:\")\n",
    "print(relative_fit_probabilities)\n",
    "# Let's check that these indeed sum to 1.0, just in case:\n",
    "print('')\n",
    "print(\"sum(relative_fit_probabilities) is:\")\n",
    "print(sum(relative_fit_probabilities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reciprocal??\n",
    "\n",
    "So that should mean that the probability of adding the speaker_output to word category 1 (index 0) should be about 0.63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T14:46:09.732901Z",
     "start_time": "2022-02-28T14:46:09.728409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fit is:\n",
      "1.5221998119928382\n",
      "reciprocal is:\n",
      "0.6569439781304512\n",
      "\n",
      "fit is:\n",
      "0.438217964235963\n",
      "reciprocal is:\n",
      "2.281969434419488\n",
      "\n",
      "fit is:\n",
      "0.4510492707459754\n",
      "reciprocal is:\n",
      "2.217052692150756\n",
      "\n",
      "fit is:\n",
      "0.00041301987043249446\n",
      "reciprocal is:\n",
      "2421.191016676385\n"
     ]
    }
   ],
   "source": [
    "# But what does Wedel (2012) mean when he says \"reciprocal\" in the Appendix? \n",
    "# Does he mean reciprocal in the mathematical sense of 1/fit?\n",
    "# We can't imagine he does; but who knows! Let's check what that would give us:\n",
    "\n",
    "for fit in category_similarities:\n",
    "    print('')\n",
    "    print(\"fit is:\")\n",
    "    print(fit)\n",
    "    reciprocal = 1./fit\n",
    "    print(\"reciprocal is:\")\n",
    "    print(reciprocal)\n",
    "\n",
    "# Hmm, I can't see how this would be relevant for getting what Wedel and Winter & Wedel \n",
    "# describe in the text when they talk about the anti-ambiguity bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T14:46:09.741125Z",
     "start_time": "2022-02-28T14:46:09.735587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sum_similarity_across_categories is:\n",
      "2.411880066845209\n",
      "\n",
      "sum_normalised is:\n",
      "1.0\n",
      "\n",
      "fit_normalised_using_reciprocal_per_category are:\n",
      "[0.6311258312209149, 0.1816914407394898, 0.18701148408923898, 0.00017124395035642603]\n"
     ]
    }
   ],
   "source": [
    "# Or do they make use of the reciprocal somehow to normalise the similarity measures\n",
    "# to get the relative fit? Because the reciprocal is what to multiply a value by to get 1\n",
    "# So to normalise the fit values per category, you could also multiply each of them with \n",
    "# the reciprocal of the sum similarity across all categories.\n",
    "\n",
    "sum_similarity_across_categories = sum(category_similarities)\n",
    "print('')\n",
    "print(\"sum_similarity_across_categories is:\")\n",
    "print(sum_similarity_across_categories)\n",
    "\n",
    "sum_normalised = sum_similarity_across_categories * (1./sum_similarity_across_categories)\n",
    "print('')\n",
    "print(\"sum_normalised is:\")\n",
    "print(sum_normalised)\n",
    "\n",
    "\n",
    "fit_normalised_using_reciprocal_per_category = []\n",
    "for fit in category_similarities:\n",
    "    fit_normalised_using_reciprocal = fit*(1./sum_similarity_across_categories)\n",
    "    fit_normalised_using_reciprocal_per_category.append(fit_normalised_using_reciprocal)\n",
    "    \n",
    "print('')\n",
    "print(\"fit_normalised_using_reciprocal_per_category are:\")\n",
    "print(fit_normalised_using_reciprocal_per_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so this roundabout normalising procedure using the reciprocal does get us the same values as our relative_fit() function..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried having a look in Andy's code to see if I could find how the anti-ambiguity bias is implemented there, but it's a bit hard to figure out, because there's a part of the code that is for the case where \"category competition\" is switched on, and it's not entirely clear to me whether that's the same as the anti-ambiguity bias, or not. But if it is: it indeed works as I described above: When category competition is turned on, the probability of a given exemplar being added to its most-similar category is proportional to its similarity to that category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Model description continued:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pressures at play for continuer signals\n",
    "\n",
    "\n",
    "#### Production:\n",
    "\n",
    "1. *Weaken* the pressure for reuse of features: i.e. the within-segment similarity bias. --> This could simply consist of changing the weighting of the within-word similarity bias relative to the within-segment similarity bias. Wedel (2012) used 0.9:0.1 (word:segment). We could try a couple of other weight ratios. For example: \n",
    "    1. 1.8:0.1\n",
    "    2. 2.7:0.1\n",
    "    3. 3.6:0.1\n",
    "    4. 0.9:0.0\n",
    "    \n",
    "    In other words, making the weighting of the word-similarity bias relative to the segment-similarity bias either 2, 3, or 4 times as high as in Wedel (2012). And, in the case of option D, removing the influence of the segment-similarity bias altogether.\n",
    "\n",
    "\n",
    "2. *Strengthen* the pressure for minimal effort. This would mean strenthening the effect of the bias $b$ shown in Equation (2), by decreasing the value of $G$. Let's try the following values of $G$ for the continuers:\n",
    "    1. $G = 2500$\n",
    "    2. $G = 1666.66...$\n",
    "    3. $G = 1250$\n",
    "    \n",
    "    These values produce a minimal effort bias that is, respectively, 2, 3, and 4 times as strong for the continuer words compared to the regular vocabulary words.\n",
    "    \n",
    "Let's have a look at how the bias value for segments at the edges of a dimension (i.e. segments with value 0 or 100) turn out with these different values of G. As mentioned above, with the bias of $G=5000$ that is used in Wedel (2012), these segment values result in a bias value of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T14:46:10.565421Z",
     "start_time": "2022-02-28T14:46:10.557558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias_edge_left_1000 is:\n",
      "1.0\n",
      "bias_edge_right_1000 is:\n",
      "1.0\n",
      "bias_edge_left_500 is:\n",
      "1.500006000024\n",
      "bias_edge_right_500 is:\n",
      "1.500006000024\n",
      "bias_edge_left_250 is:\n",
      "2.0\n",
      "bias_edge_right_250 is:\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "\n",
    "g = 2500\n",
    "\n",
    "bias_edge_left_1000 = bias(0, n, g)\n",
    "print(\"bias_edge_left_1000 is:\")\n",
    "print(bias_edge_left_1000)\n",
    "\n",
    "bias_edge_right_1000 = bias(100, n, g)\n",
    "print(\"bias_edge_right_1000 is:\")\n",
    "print(bias_edge_right_1000)\n",
    "\n",
    "\n",
    "g = 1666.66\n",
    "\n",
    "bias_edge_left_500 = bias(0, n, g)\n",
    "print(\"bias_edge_left_500 is:\")\n",
    "print(bias_edge_left_500)\n",
    "\n",
    "bias_edge_right_500 = bias(100, n, g)\n",
    "print(\"bias_edge_right_500 is:\")\n",
    "print(bias_edge_right_500)\n",
    "\n",
    "\n",
    "g = 1250\n",
    "\n",
    "bias_edge_left_250 = bias(0, n, g)\n",
    "print(\"bias_edge_left_250 is:\")\n",
    "print(bias_edge_left_250)\n",
    "\n",
    "bias_edge_right_250 = bias(100, n, g)\n",
    "print(\"bias_edge_right_250 is:\")\n",
    "print(bias_edge_right_250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, compared to the bias parameter $G=5000$ that is used in Wedel (2012), which produces a bias at the edges of 0.5, we can state that:\n",
    "\n",
    "- $G=2500$ yields a minimal effort bias that is 2 times as strong as the minimal effort bias used in Wedel (2012)\n",
    "- $G=1666.66$ yields a minimal effort bias that is 3 times as strong as the minimal effort bias used in Wedel (2012)\n",
    "- $G=1250$ yields a minimal effort bias that is 4 times as strong as the minimal effort bias used in Wedel (2012)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perception:\n",
    "\n",
    "Nothing in particular for now. (This is where we could implement our idea of an extra anti-ambiguity pressure that acts *between* the class of \"regular vocabulary\" on the one hand, and the class of \"collatoral signals\" on the other hand. But we will not implement this pressure for now, because we don't find it sufficiently independently motivated from the easing of the reuse of features pressure.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measures:\n",
    "\n",
    "### Measure to calculate \"squareness\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T14:46:11.314130Z",
     "start_time": "2022-02-28T14:46:11.148211Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_possible_pairings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3y/tfh7pgln7q50mmdy6_j5yq2h0000gp/T/ipykernel_26164/1688830909.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistances_per_dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m \u001b[0mdistances_per_dimension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentroids_square_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_possible_pairings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_dimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"distances_per_dimension are:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances_per_dimension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_possible_pairings' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# NOTE that this code only works for a simulation with exactly 4 words.\n",
    "\n",
    "\n",
    "\n",
    "# Let's make up some example values for the centroids, and enumerate all the\n",
    "# possible ways in which they can be a square. Because the way the values\n",
    "# line up on Dimension 1 determines how the values on Dimension 2 should\n",
    "# line up in order to form a square, I believe there are only three possible\n",
    "# ways of forming a square. The comments above the centroid arrays show\n",
    "# the corresponding translation into \"pairings\" between segment values along\n",
    "# the different dimensions.\n",
    "\n",
    "# dimension 1: [[0, 1], [2, 3]] # Meaning: along Dimension 1, the segments of \n",
    "                                # categories 0 and 1 lie close together, and \n",
    "                                # the segments of categories 2 and 3\n",
    "                                # lie close together.\n",
    "# dimension 2: [[0, 2], [1, 3]] # These are the corresponding pairings of categories\n",
    "                                # that are necessary along Dimension 2, in order to\n",
    "                                # complement those along Dimension 1, in such a way\n",
    "                                # that you get a square.\n",
    "centroids_square_1 = np.array([[15, 25], \n",
    "                               [20, 80], \n",
    "                               [65, 15], \n",
    "                               [75, 85]])\n",
    "\n",
    "# dimension 1: [[0, 2], [1, 3]]\n",
    "# dimension 2: [[0, 1], [2, 3]]\n",
    "centroids_square_2 = np.array([[15, 25], \n",
    "                               [65, 15], \n",
    "                               [20, 80], \n",
    "                               [75, 85]])\n",
    "\n",
    "# dimension 1: [[0, 3], [1, 2]]\n",
    "# dimension 2: [[0, 1], [2, 3]]\n",
    "centroids_square_3 = np.array([[15, 25], \n",
    "                               [65, 15], \n",
    "                               [75, 85], \n",
    "                               [20, 80]])\n",
    "\n",
    "\n",
    "# So these are the three possible pairings between segment values along\n",
    "# the different dimensions that result in a square (separated by dimension):\n",
    "\n",
    "possible_pairings_dimension_1 = np.array([[[0, 1], [2, 3]], \n",
    "                                          [[0, 2], [1, 3]], \n",
    "                                          [[0, 3], [1, 2]]])\n",
    " \n",
    "corresponding_mappings_dimension_2 = np.array([[[0, 2], [1, 3]], \n",
    "                                               [[0, 1], [2, 3]], \n",
    "                                               [[0, 1], [2, 3]]])\n",
    "n_dimensions = 2\n",
    "\n",
    "def pairwise_distances(centroids, all_possible_pairings, n_dimensions):\n",
    "    distances_per_dimension = np.zeros((len(all_possible_pairings), n_dimensions))\n",
    "    for p in range(len(all_possible_pairings)):\n",
    "        pairing = all_possible_pairings[p]\n",
    "        print('')\n",
    "        print('')\n",
    "        print(\"pairing is:\")\n",
    "        print(pairing)\n",
    "        distance_per_dimension = np.zeros(n_dimensions)\n",
    "        for d in range(n_dimensions):\n",
    "            total_distance = 0.\n",
    "            for pair in pairing:\n",
    "                print('')\n",
    "                print(\"pair is:\")\n",
    "                print(pair)\n",
    "                index_i = pair[0]\n",
    "                index_j = pair[1]\n",
    "                segment_value_i = centroids[index_i][d]\n",
    "                segment_value_j = centroids[index_j][d]\n",
    "                print(\"segment_value_i is:\")\n",
    "                print(segment_value_i)      \n",
    "                print(\"segment_value_j is:\")\n",
    "                print(segment_value_j)   \n",
    "                total_distance += abs(segment_value_i-segment_value_j)\n",
    "                print(\"distance is:\")\n",
    "                print(abs(segment_value_i-segment_value_j))\n",
    "            distance_per_dimension[d] = total_distance\n",
    "        print(\"total_distance is:\")\n",
    "        print(total_distance)\n",
    "        distances_per_dimension[p] = distance_per_dimension\n",
    "    return distances_per_dimension\n",
    "\n",
    "distances_per_dimension = pairwise_distances(centroids_square_1, all_possible_pairings, n_dimensions)\n",
    "print(\"distances_per_dimension are:\")\n",
    "print(distances_per_dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XXXXXX's [name redacted] implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T16:14:09.282580Z",
     "start_time": "2022-03-01T16:14:09.253854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "pairing is:\n",
      "[[[0 1]\n",
      "  [0 2]]\n",
      "\n",
      " [[2 3]\n",
      "  [1 3]]]\n",
      "\n",
      "pair is:\n",
      "[[0 1]\n",
      " [0 2]]\n",
      "segment_value_i is:\n",
      "15\n",
      "segment_value_j is:\n",
      "20\n",
      "distance is:\n",
      "5\n",
      "\n",
      "pair is:\n",
      "[[2 3]\n",
      " [1 3]]\n",
      "segment_value_i is:\n",
      "65\n",
      "segment_value_j is:\n",
      "75\n",
      "distance is:\n",
      "10\n",
      "\n",
      "pair is:\n",
      "[[0 1]\n",
      " [0 2]]\n",
      "segment_value_i is:\n",
      "25\n",
      "segment_value_j is:\n",
      "15\n",
      "distance is:\n",
      "10\n",
      "\n",
      "pair is:\n",
      "[[2 3]\n",
      " [1 3]]\n",
      "segment_value_i is:\n",
      "80\n",
      "segment_value_j is:\n",
      "85\n",
      "distance is:\n",
      "5\n",
      "total_distance is:\n",
      "15.0\n",
      "\n",
      "\n",
      "pairing is:\n",
      "[[[0 2]\n",
      "  [0 1]]\n",
      "\n",
      " [[1 3]\n",
      "  [2 3]]]\n",
      "\n",
      "pair is:\n",
      "[[0 2]\n",
      " [0 1]]\n",
      "segment_value_i is:\n",
      "15\n",
      "segment_value_j is:\n",
      "65\n",
      "distance is:\n",
      "50\n",
      "\n",
      "pair is:\n",
      "[[1 3]\n",
      " [2 3]]\n",
      "segment_value_i is:\n",
      "20\n",
      "segment_value_j is:\n",
      "75\n",
      "distance is:\n",
      "55\n",
      "\n",
      "pair is:\n",
      "[[0 2]\n",
      " [0 1]]\n",
      "segment_value_i is:\n",
      "25\n",
      "segment_value_j is:\n",
      "80\n",
      "distance is:\n",
      "55\n",
      "\n",
      "pair is:\n",
      "[[1 3]\n",
      " [2 3]]\n",
      "segment_value_i is:\n",
      "15\n",
      "segment_value_j is:\n",
      "85\n",
      "distance is:\n",
      "70\n",
      "total_distance is:\n",
      "125.0\n",
      "\n",
      "\n",
      "pairing is:\n",
      "[[[0 3]\n",
      "  [0 1]]\n",
      "\n",
      " [[1 2]\n",
      "  [2 3]]]\n",
      "\n",
      "pair is:\n",
      "[[0 3]\n",
      " [0 1]]\n",
      "segment_value_i is:\n",
      "15\n",
      "segment_value_j is:\n",
      "75\n",
      "distance is:\n",
      "60\n",
      "\n",
      "pair is:\n",
      "[[1 2]\n",
      " [2 3]]\n",
      "segment_value_i is:\n",
      "20\n",
      "segment_value_j is:\n",
      "65\n",
      "distance is:\n",
      "45\n",
      "\n",
      "pair is:\n",
      "[[0 3]\n",
      " [0 1]]\n",
      "segment_value_i is:\n",
      "25\n",
      "segment_value_j is:\n",
      "80\n",
      "distance is:\n",
      "55\n",
      "\n",
      "pair is:\n",
      "[[1 2]\n",
      " [2 3]]\n",
      "segment_value_i is:\n",
      "15\n",
      "segment_value_j is:\n",
      "85\n",
      "distance is:\n",
      "70\n",
      "total_distance is:\n",
      "125.0\n",
      "distances_per_dimension are:\n",
      "[[ 15.  15.]\n",
      " [105. 125.]\n",
      " [105. 125.]]\n",
      "distances_possibilities are:\n",
      "[ 30. 230. 230.]\n",
      "Smallest distance:  30.0\n",
      "Index smallest distance:  0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "centroids_square = np.array([[15, 25], \n",
    "                             [20, 80], \n",
    "                             [65, 15], \n",
    "                             [75, 85]])\n",
    "\n",
    "all_possible_pairings = np.array([[[[0, 1], [0, 2]], [[2, 3], [1, 3]]], \n",
    "                                 [[[0, 2], [0, 1]], [[1, 3], [2, 3]]], \n",
    "                                 [[[0, 3], [0, 1]], [[1, 2], [2, 3]]]])\n",
    "\n",
    "# possible_pairings_dimension_1 = np.array([[[0, 1], [2, 3]], \n",
    "#                                           [[0, 2], [1, 3]], \n",
    "#                                           [[0, 3], [1, 2]]])\n",
    " \n",
    "# corresponding_mappings_dimension_2 = np.array([[[0, 2], [1, 3]], \n",
    "#                                                [[0, 1], [2, 3]], \n",
    "#                                                [[0, 1], [2, 3]]])\n",
    "\n",
    "n_dimensions = 2\n",
    "\n",
    "\n",
    "def pairwise_distances(centroids, all_possible_pairings, n_dimensions):\n",
    "    distances_per_dimension = np.zeros((len(all_possible_pairings), n_dimensions))\n",
    "    distances_pairings = np.zeros(len(all_possible_pairings))\n",
    "    for p in range(len(all_possible_pairings)):\n",
    "        pairing = all_possible_pairings[p]\n",
    "        print('')\n",
    "        print('')\n",
    "        print(\"pairing is:\")\n",
    "        print(pairing)\n",
    "        distance_per_dimension = np.zeros(n_dimensions)\n",
    "        for d in range(n_dimensions):\n",
    "            total_distance = 0.\n",
    "            for pair in pairing:\n",
    "                print('')\n",
    "                print(\"pair is:\")\n",
    "                print(pair)\n",
    "                index_i = pair[d][0]\n",
    "                index_j = pair[d][1]\n",
    "                segment_value_i = centroids[index_i][d]\n",
    "                segment_value_j = centroids[index_j][d]\n",
    "                print(\"segment_value_i is:\")\n",
    "                print(segment_value_i)      \n",
    "                print(\"segment_value_j is:\")\n",
    "                print(segment_value_j)   \n",
    "                total_distance += abs(segment_value_i-segment_value_j)\n",
    "                print(\"distance is:\")\n",
    "                print(abs(segment_value_i-segment_value_j))\n",
    "            distance_per_dimension[d] = total_distance\n",
    "        print(\"total_distance is:\")\n",
    "        print(total_distance)\n",
    "        distances_per_dimension[p] = distance_per_dimension\n",
    "        distances_pairings[p] = np.sum(distances_per_dimension[p])\n",
    "    return distances_per_dimension, distances_pairings\n",
    "\n",
    "distances_per_dimension, distances_pairings = pairwise_distances(centroids_square, all_possible_pairings, n_dimensions)\n",
    "print(\"distances_per_dimension are:\")\n",
    "print(distances_per_dimension)\n",
    "print(\"distances_possibilities are:\")\n",
    "print(distances_pairings)\n",
    "\n",
    "def choose_fitting_pairing(distances_pairings):\n",
    "    smallest_distance = np.amin(distances_pairings)\n",
    "    #smallest_index = np.where(smallest_distance)\n",
    "    smallest_index = np.argmin(distances_pairings)\n",
    "    #return smallest_distance, smallest_index[0][0]\n",
    "    return smallest_distance, smallest_index\n",
    "\n",
    "smallest_distance, smallest_index = choose_fitting_pairing(distances_pairings)\n",
    "print(\"Smallest distance: \", smallest_distance)\n",
    "print(\"Index smallest distance: \", smallest_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T14:46:11.378445Z",
     "start_time": "2022-02-28T14:46:11.354573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "CENTROIDS SQUARE 1 RESULTS\n",
      "\n",
      "\n",
      "\n",
      "pairing is:\n",
      "[[[0 1]\n",
      "  [0 2]]\n",
      "\n",
      " [[2 3]\n",
      "  [1 3]]]\n",
      "\n",
      "pair is:\n",
      "[[0 1]\n",
      " [0 2]]\n",
      "segment_value_i is:\n",
      "15\n",
      "segment_value_j is:\n",
      "20\n",
      "distance is:\n",
      "5\n",
      "\n",
      "pair is:\n",
      "[[2 3]\n",
      " [1 3]]\n",
      "segment_value_i is:\n",
      "65\n",
      "segment_value_j is:\n",
      "75\n",
      "distance is:\n",
      "10\n",
      "\n",
      "pair is:\n",
      "[[0 1]\n",
      " [0 2]]\n",
      "segment_value_i is:\n",
      "25\n",
      "segment_value_j is:\n",
      "15\n",
      "distance is:\n",
      "10\n",
      "\n",
      "pair is:\n",
      "[[2 3]\n",
      " [1 3]]\n",
      "segment_value_i is:\n",
      "80\n",
      "segment_value_j is:\n",
      "85\n",
      "distance is:\n",
      "5\n",
      "total_distance is:\n",
      "15.0\n",
      "\n",
      "\n",
      "pairing is:\n",
      "[[[0 2]\n",
      "  [0 1]]\n",
      "\n",
      " [[1 3]\n",
      "  [2 3]]]\n",
      "\n",
      "pair is:\n",
      "[[0 2]\n",
      " [0 1]]\n",
      "segment_value_i is:\n",
      "15\n",
      "segment_value_j is:\n",
      "65\n",
      "distance is:\n",
      "50\n",
      "\n",
      "pair is:\n",
      "[[1 3]\n",
      " [2 3]]\n",
      "segment_value_i is:\n",
      "20\n",
      "segment_value_j is:\n",
      "75\n",
      "distance is:\n",
      "55\n",
      "\n",
      "pair is:\n",
      "[[0 2]\n",
      " [0 1]]\n",
      "segment_value_i is:\n",
      "25\n",
      "segment_value_j is:\n",
      "80\n",
      "distance is:\n",
      "55\n",
      "\n",
      "pair is:\n",
      "[[1 3]\n",
      " [2 3]]\n",
      "segment_value_i is:\n",
      "15\n",
      "segment_value_j is:\n",
      "85\n",
      "distance is:\n",
      "70\n",
      "total_distance is:\n",
      "125.0\n",
      "\n",
      "\n",
      "pairing is:\n",
      "[[[0 3]\n",
      "  [0 1]]\n",
      "\n",
      " [[1 2]\n",
      "  [2 3]]]\n",
      "\n",
      "pair is:\n",
      "[[0 3]\n",
      " [0 1]]\n",
      "segment_value_i is:\n",
      "15\n",
      "segment_value_j is:\n",
      "75\n",
      "distance is:\n",
      "60\n",
      "\n",
      "pair is:\n",
      "[[1 2]\n",
      " [2 3]]\n",
      "segment_value_i is:\n",
      "20\n",
      "segment_value_j is:\n",
      "65\n",
      "distance is:\n",
      "45\n",
      "\n",
      "pair is:\n",
      "[[0 3]\n",
      " [0 1]]\n",
      "segment_value_i is:\n",
      "25\n",
      "segment_value_j is:\n",
      "80\n",
      "distance is:\n",
      "55\n",
      "\n",
      "pair is:\n",
      "[[1 2]\n",
      " [2 3]]\n",
      "segment_value_i is:\n",
      "15\n",
      "segment_value_j is:\n",
      "85\n",
      "distance is:\n",
      "70\n",
      "total_distance is:\n",
      "125.0\n",
      "distances_per_dimension_1 are:\n",
      "[[ 15.  15.]\n",
      " [105. 125.]\n",
      " [105. 125.]]\n",
      "distances_possibilities_1 are:\n",
      "[ 30. 230. 230.]\n",
      "Smallest distance:  30.0\n",
      "Index smallest distance:  0\n",
      "\n",
      "\n",
      "CENTROIDS SQUARE 2 RESULTS\n",
      "\n",
      "\n",
      "\n",
      "pairing is:\n",
      "[[[0 1]\n",
      "  [0 2]]\n",
      "\n",
      " [[2 3]\n",
      "  [1 3]]]\n",
      "\n",
      "pair is:\n",
      "[[0 1]\n",
      " [0 2]]\n",
      "segment_value_i is:\n",
      "15\n",
      "segment_value_j is:\n",
      "65\n",
      "distance is:\n",
      "50\n",
      "\n",
      "pair is:\n",
      "[[2 3]\n",
      " [1 3]]\n",
      "segment_value_i is:\n",
      "20\n",
      "segment_value_j is:\n",
      "75\n",
      "distance is:\n",
      "55\n",
      "\n",
      "pair is:\n",
      "[[0 1]\n",
      " [0 2]]\n",
      "segment_value_i is:\n",
      "25\n",
      "segment_value_j is:\n",
      "80\n",
      "distance is:\n",
      "55\n",
      "\n",
      "pair is:\n",
      "[[2 3]\n",
      " [1 3]]\n",
      "segment_value_i is:\n",
      "15\n",
      "segment_value_j is:\n",
      "85\n",
      "distance is:\n",
      "70\n",
      "total_distance is:\n",
      "125.0\n",
      "\n",
      "\n",
      "pairing is:\n",
      "[[[0 2]\n",
      "  [0 1]]\n",
      "\n",
      " [[1 3]\n",
      "  [2 3]]]\n",
      "\n",
      "pair is:\n",
      "[[0 2]\n",
      " [0 1]]\n",
      "segment_value_i is:\n",
      "15\n",
      "segment_value_j is:\n",
      "20\n",
      "distance is:\n",
      "5\n",
      "\n",
      "pair is:\n",
      "[[1 3]\n",
      " [2 3]]\n",
      "segment_value_i is:\n",
      "65\n",
      "segment_value_j is:\n",
      "75\n",
      "distance is:\n",
      "10\n",
      "\n",
      "pair is:\n",
      "[[0 2]\n",
      " [0 1]]\n",
      "segment_value_i is:\n",
      "25\n",
      "segment_value_j is:\n",
      "15\n",
      "distance is:\n",
      "10\n",
      "\n",
      "pair is:\n",
      "[[1 3]\n",
      " [2 3]]\n",
      "segment_value_i is:\n",
      "80\n",
      "segment_value_j is:\n",
      "85\n",
      "distance is:\n",
      "5\n",
      "total_distance is:\n",
      "15.0\n",
      "\n",
      "\n",
      "pairing is:\n",
      "[[[0 3]\n",
      "  [0 1]]\n",
      "\n",
      " [[1 2]\n",
      "  [2 3]]]\n",
      "\n",
      "pair is:\n",
      "[[0 3]\n",
      " [0 1]]\n",
      "segment_value_i is:\n",
      "15\n",
      "segment_value_j is:\n",
      "75\n",
      "distance is:\n",
      "60\n",
      "\n",
      "pair is:\n",
      "[[1 2]\n",
      " [2 3]]\n",
      "segment_value_i is:\n",
      "65\n",
      "segment_value_j is:\n",
      "20\n",
      "distance is:\n",
      "45\n",
      "\n",
      "pair is:\n",
      "[[0 3]\n",
      " [0 1]]\n",
      "segment_value_i is:\n",
      "25\n",
      "segment_value_j is:\n",
      "15\n",
      "distance is:\n",
      "10\n",
      "\n",
      "pair is:\n",
      "[[1 2]\n",
      " [2 3]]\n",
      "segment_value_i is:\n",
      "80\n",
      "segment_value_j is:\n",
      "85\n",
      "distance is:\n",
      "5\n",
      "total_distance is:\n",
      "15.0\n",
      "distances_per_dimension_2 are:\n",
      "[[105. 125.]\n",
      " [ 15.  15.]\n",
      " [105.  15.]]\n",
      "distances_possibilities_2 are:\n",
      "[230.  30. 120.]\n",
      "Smallest distance:  30.0\n",
      "Index smallest distance:  1\n",
      "\n",
      "\n",
      "CENTROIDS SQUARE 3 RESULTS\n",
      "\n",
      "\n",
      "\n",
      "pairing is:\n",
      "[[[0 1]\n",
      "  [0 2]]\n",
      "\n",
      " [[2 3]\n",
      "  [1 3]]]\n",
      "\n",
      "pair is:\n",
      "[[0 1]\n",
      " [0 2]]\n",
      "segment_value_i is:\n",
      "15\n",
      "segment_value_j is:\n",
      "65\n",
      "distance is:\n",
      "50\n",
      "\n",
      "pair is:\n",
      "[[2 3]\n",
      " [1 3]]\n",
      "segment_value_i is:\n",
      "75\n",
      "segment_value_j is:\n",
      "20\n",
      "distance is:\n",
      "55\n",
      "\n",
      "pair is:\n",
      "[[0 1]\n",
      " [0 2]]\n",
      "segment_value_i is:\n",
      "25\n",
      "segment_value_j is:\n",
      "85\n",
      "distance is:\n",
      "60\n",
      "\n",
      "pair is:\n",
      "[[2 3]\n",
      " [1 3]]\n",
      "segment_value_i is:\n",
      "15\n",
      "segment_value_j is:\n",
      "80\n",
      "distance is:\n",
      "65\n",
      "total_distance is:\n",
      "125.0\n",
      "\n",
      "\n",
      "pairing is:\n",
      "[[[0 2]\n",
      "  [0 1]]\n",
      "\n",
      " [[1 3]\n",
      "  [2 3]]]\n",
      "\n",
      "pair is:\n",
      "[[0 2]\n",
      " [0 1]]\n",
      "segment_value_i is:\n",
      "15\n",
      "segment_value_j is:\n",
      "75\n",
      "distance is:\n",
      "60\n",
      "\n",
      "pair is:\n",
      "[[1 3]\n",
      " [2 3]]\n",
      "segment_value_i is:\n",
      "65\n",
      "segment_value_j is:\n",
      "20\n",
      "distance is:\n",
      "45\n",
      "\n",
      "pair is:\n",
      "[[0 2]\n",
      " [0 1]]\n",
      "segment_value_i is:\n",
      "25\n",
      "segment_value_j is:\n",
      "15\n",
      "distance is:\n",
      "10\n",
      "\n",
      "pair is:\n",
      "[[1 3]\n",
      " [2 3]]\n",
      "segment_value_i is:\n",
      "85\n",
      "segment_value_j is:\n",
      "80\n",
      "distance is:\n",
      "5\n",
      "total_distance is:\n",
      "15.0\n",
      "\n",
      "\n",
      "pairing is:\n",
      "[[[0 3]\n",
      "  [0 1]]\n",
      "\n",
      " [[1 2]\n",
      "  [2 3]]]\n",
      "\n",
      "pair is:\n",
      "[[0 3]\n",
      " [0 1]]\n",
      "segment_value_i is:\n",
      "15\n",
      "segment_value_j is:\n",
      "20\n",
      "distance is:\n",
      "5\n",
      "\n",
      "pair is:\n",
      "[[1 2]\n",
      " [2 3]]\n",
      "segment_value_i is:\n",
      "65\n",
      "segment_value_j is:\n",
      "75\n",
      "distance is:\n",
      "10\n",
      "\n",
      "pair is:\n",
      "[[0 3]\n",
      " [0 1]]\n",
      "segment_value_i is:\n",
      "25\n",
      "segment_value_j is:\n",
      "15\n",
      "distance is:\n",
      "10\n",
      "\n",
      "pair is:\n",
      "[[1 2]\n",
      " [2 3]]\n",
      "segment_value_i is:\n",
      "85\n",
      "segment_value_j is:\n",
      "80\n",
      "distance is:\n",
      "5\n",
      "total_distance is:\n",
      "15.0\n",
      "distances_per_dimension_3 are:\n",
      "[[105. 125.]\n",
      " [105.  15.]\n",
      " [ 15.  15.]]\n",
      "distances_possibilities_3 are:\n",
      "[230. 120.  30.]\n",
      "Smallest distance:  30.0\n",
      "Index smallest distance:  2\n"
     ]
    }
   ],
   "source": [
    "# XXXXX [name redacted] checking the results for the other possible squares of centroids:\n",
    "\n",
    "\n",
    "centroids_square_1 = np.array([[15, 25], \n",
    "                               [20, 80], \n",
    "                               [65, 15], \n",
    "                               [75, 85]])\n",
    "\n",
    "# dimension 1: [[0, 2], [1, 3]]\n",
    "# dimension 2: [[0, 1], [2, 3]]\n",
    "centroids_square_2 = np.array([[15, 25], \n",
    "                               [65, 15], \n",
    "                               [20, 80], \n",
    "                               [75, 85]])\n",
    "\n",
    "# dimension 1: [[0, 3], [1, 2]]\n",
    "# dimension 2: [[0, 1], [2, 3]]\n",
    "centroids_square_3 = np.array([[15, 25], \n",
    "                               [65, 15], \n",
    "                               [75, 85], \n",
    "                               [20, 80]])\n",
    "\n",
    "\n",
    "print('')\n",
    "print('')\n",
    "print('CENTROIDS SQUARE 1 RESULTS')\n",
    "print('')\n",
    "\n",
    "distances_per_dimension_1, distances_pairings_1 = pairwise_distances(centroids_square_1, all_possible_pairings, n_dimensions)\n",
    "print(\"distances_per_dimension_1 are:\")\n",
    "print(distances_per_dimension_1)\n",
    "print(\"distances_possibilities_1 are:\")\n",
    "print(distances_pairings_1)\n",
    "\n",
    "smallest_distance_1, smallest_index_1 = choose_fitting_pairing(distances_pairings_1)\n",
    "print(\"Smallest distance: \", smallest_distance_1)\n",
    "print(\"Index smallest distance: \", smallest_index_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('')\n",
    "print('')\n",
    "print('CENTROIDS SQUARE 2 RESULTS')\n",
    "print('')\n",
    "\n",
    "distances_per_dimension_2, distances_pairings_2 = pairwise_distances(centroids_square_2, all_possible_pairings, n_dimensions)\n",
    "print(\"distances_per_dimension_2 are:\")\n",
    "print(distances_per_dimension_2)\n",
    "print(\"distances_possibilities_2 are:\")\n",
    "print(distances_pairings_2)\n",
    "\n",
    "smallest_distance_2, smallest_index_2 = choose_fitting_pairing(distances_pairings_2)\n",
    "print(\"Smallest distance: \", smallest_distance_2)\n",
    "print(\"Index smallest distance: \", smallest_index_2)\n",
    "\n",
    "\n",
    "\n",
    "print('')\n",
    "print('')\n",
    "print('CENTROIDS SQUARE 3 RESULTS')\n",
    "print('')\n",
    "\n",
    "distances_per_dimension_3, distances_pairings_3 = pairwise_distances(centroids_square_3, all_possible_pairings, n_dimensions)\n",
    "print(\"distances_per_dimension_3 are:\")\n",
    "print(distances_per_dimension_3)\n",
    "print(\"distances_possibilities_3 are:\")\n",
    "print(distances_pairings_3)\n",
    "\n",
    "smallest_distance_3, smallest_index_3 = choose_fitting_pairing(distances_pairings_3)\n",
    "print(\"Smallest distance: \", smallest_distance_3)\n",
    "print(\"Index smallest distance: \", smallest_index_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T14:46:11.382063Z",
     "start_time": "2022-02-28T14:46:11.380038Z"
    }
   },
   "outputs": [],
   "source": [
    "# Excluding the cases in which the cluster centroids overlap\n",
    "\n",
    "# Dus per cluster x en per dimensie d de exemplar nemen die het verst uit het midden ligt, \n",
    "# en dan checken of er nog wel een positive distance is tussen die exemplar en de dichtstbijzijnde \n",
    "# exemplar van de corresponderende cluster y die met dit cluster x ge\"paired\" is op de *andere* dimensie\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Wedel, A. (2012). Lexical contrast maintenance and the organization of sublexical contrast systems. Language and Cognition, 4(4), 319–355. https://doi.org/10.1515/langcog-2012-0018\n",
    "\n",
    "Winter, B., & Wedel, A. (2016). The Co-evolution of Speech and the Lexicon: The Interaction of Functional Pressures, Redundancy, and Category Variation. Topics in Cognitive Science, 8(2), 503–513. https://doi.org/10.1111/tops.12202"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
